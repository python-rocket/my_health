from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field, field_validator
from typing import Optional, Dict, List
import sys
import os
from pathlib import Path
import csv
import io
import uuid
import pandas as pd
import json

# Add current directory to path for imports
current_dir = os.path.dirname(__file__)
sys.path.insert(0, current_dir)
from modules.ai_doctor.ask.ask import Ask
from modules.ai_doctor.ask.schema_extractor import extract_schema
from modules.youtube_summarizer.src.utils.psql_client import PSQLClient

app = FastAPI()

# Enable CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # In production, specify your frontend URL
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Extract schema on startup
schema_path = Path(__file__).parent / "ask" / "cache" / "db_schema.txt"
try:
    connection_string = os.getenv("PSQL_CONNECTION_STRING")
    if connection_string:
        extract_schema(connection_string, str(schema_path))
        print("Database schema extracted successfully")
    else:
        print("Warning: PSQL_CONNECTION_STRING not set, skipping schema extraction")
except Exception as e:
    print(f"Warning: Failed to extract schema on startup: {e}")

# Initialize Ask instance
ask_instance = Ask()

class PreferencesRequest(BaseModel):
    favoriteChannels: Optional[List[str]] = None
    favoriteSolutions: Optional[List[str]] = None
    pubmedPreferences: Optional[Dict] = None

class AskRequest(BaseModel):
    prompt: str
    preferences: Optional[PreferencesRequest] = None
    max_iterations: Optional[int] = None

class AgentRequest(BaseModel):
    prompt: str
    include_trace: Optional[bool] = False

class TestingResultRow(BaseModel):
    # id is auto-generated by database, not included in CSV
    test_object: Optional[str] = None
    result_value: Optional[float] = None
    result_unit: Optional[str] = None
    reference_value: Optional[float] = None
    comments: Optional[str] = None
    flag: Optional[str] = None

class TestingResultsResponse(BaseModel):
    success: bool
    message: str
    rows_inserted: Optional[int] = None
    rows_invalid: Optional[int] = None
    invalid_row_numbers: Optional[List[int]] = None
    trace: Optional[Dict] = None

class ProcessTestingResultsRequest(BaseModel):
    file_id: str


@app.post("/ask")
async def ask_endpoint(request: AskRequest):
    try:
        prompt = request.prompt
        preferences = request.preferences.model_dump() if request.preferences else None
        max_iterations = request.max_iterations
        response = ask_instance.ask_directly(
            prompt=prompt, 
            preferences=preferences,
            max_iterations=max_iterations
        )
        return {"response": response}
    except Exception as e:
        return {"error": str(e)}, 500


@app.get("/health")
async def health():
    return {"status": "ok"}

# Initialize PSQL client for testing results
psql_client = None
try:
    connection_string = os.getenv("PSQL_CONNECTION_STRING")
    if connection_string:
        psql_client = PSQLClient(connection_string)
except Exception as e:
    print(f"Warning: Failed to initialize PSQL client: {e}")

@app.post("/agent")
async def agent_endpoint(request: AgentRequest):
    """
    Agent endpoint similar to /ask endpoint.
    Accepts a text prompt and returns agent response.
    Optionally includes trace information if include_trace is True.
    """
    try:
        # Import agent from SDK
        sys.path.insert(0, os.path.join(current_dir, "agent", "sdk"))
        
        if request.include_trace:
            from file_agent import run_agent_async_with_trace
            agent_result = await run_agent_async_with_trace(request.prompt)
            return {
                "response": agent_result["final_output"],
                "trace": {
                    "tool_calls": agent_result.get("tool_calls", []),
                    "tool_usage_summary": agent_result.get("tool_usage_summary", {}),
                    "messages_count": agent_result.get("messages_count", 0),
                    "trace_id": agent_result.get("trace_id")
                }
            }
        else:
            from file_agent import run_agent_async
            response = await run_agent_async(request.prompt)
            return {"response": response}
    except Exception as e:
        return {"error": str(e)}, 500

@app.post("/upload-testing-results")
async def upload_testing_results(file: UploadFile = File(...)):
    """
    Upload a testing results file (PDF, CSV, or image).
    Stores the file in the testing_results directory next to preferences.
    """
    try:
        # Determine file storage location (next to preferences)
        frontend_dist_path = Path(current_dir) / "modules" / "frontend" / "dist"
        testing_results_dir = frontend_dist_path / "testing_results"
        testing_results_dir.mkdir(parents=True, exist_ok=True)
        
        # Generate unique filename
        file_ext = Path(file.filename).suffix
        file_id = str(uuid.uuid4())
        file_path = testing_results_dir / f"{file_id}{file_ext}"
        
        # Save file
        with open(file_path, "wb") as f:
            content = await file.read()
            f.write(content)
        
        return {
            "success": True,
            "file_id": file_id,
            "file_path": str(file_path),
            "filename": file.filename
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error uploading file: {str(e)}")

@app.post("/process-testing-results")
async def process_testing_results(request: ProcessTestingResultsRequest):
    """
    Process an uploaded testing results file using the agent.
    Extracts data, validates with Pydantic, and inserts into database.
    """
    try:
        file_id = request.file_id
        
        # Find the uploaded file
        frontend_dist_path = Path(current_dir) / "modules" / "frontend" / "dist"
        testing_results_dir = frontend_dist_path / "testing_results"
        
        # Find file by ID (check common extensions)
        file_path = None
        for ext in ['.pdf', '.csv', '.png', '.jpg', '.jpeg', '.gif', '.webp']:
            candidate = testing_results_dir / f"{file_id}{ext}"
            if candidate.exists():
                file_path = candidate
                break
        
        if not file_path or not file_path.exists():
            raise HTTPException(status_code=404, detail=f"File with ID {file_id} not found")
        
        # Load agent instructions
        instructions_path = Path(current_dir) / "agent" / "sdk" / "testing_results_instructions.txt"
        instructions = ""
        if instructions_path.exists():
            with open(instructions_path, 'r', encoding='utf-8') as f:
                instructions = f.read()
        
        # Determine file type and construct agent prompt
        # NOTE: For PDFs, we now use Vision API (read_pdf_with_vision) instead of read_pdf
        # to handle scanned/image-based PDFs better. The read_pdf tool is kept but deactivated.
        file_ext = file_path.suffix.lower()
        if file_ext == '.pdf':
            read_command = f"read_pdf_with_vision('{file_path}')"
        elif file_ext in ['.png', '.jpg', '.jpeg', '.gif', '.webp']:
            read_command = f"read_image('{file_path}')"
        elif file_ext == '.csv':
            read_command = f"read_csv('{file_path}')"
        else:
            read_command = f"read_file('{file_path}')"
        
        # Create agent prompt
        agent_prompt = f"""{instructions}

Now, please read the file at '{file_path}' using the {read_command} tool and extract all testing results. Return ONLY a valid CSV string matching the exact schema specified above, with no additional text or markdown formatting.

IMPORTANT: You MUST extract at least one test result row. If you cannot find any test results, explain why in your response."""
        
        print(f"\nüìù [AGENT PROMPT] Created agent prompt")
        print(f"   üìè Prompt length: {len(agent_prompt)} characters")
        print(f"   üìÑ File to process: {file_path}")
        print(f"   üîß Read command: {read_command}")
        
        # Run agent with trace information
        sys.path.insert(0, os.path.join(current_dir, "agent", "sdk"))
        from file_agent import run_agent_async_with_trace
        
        try:
            print(f"\nü§ñ [AGENT EXECUTION] Starting agent...")
            agent_result = await run_agent_async_with_trace(agent_prompt)
            agent_response = agent_result["final_output"]
            
            print(f"\nüì§ [AGENT RESPONSE] Received agent response")
            print(f"   üìè Response length: {len(agent_response)} characters")
            print(f"   üìã Response type: {type(agent_response)}")
            print(f"   üìÑ Full response:\n{'='*80}\n{agent_response}\n{'='*80}")
            
            # Check if response is empty or only contains header
            if len(agent_response.strip()) < 100:
                print(f"\n‚ö†Ô∏è  WARNING: Agent response is very short ({len(agent_response)} chars)")
                print(f"   This might indicate the agent didn't extract any data")
            
            trace_info = {
                "tool_calls": agent_result.get("tool_calls", []),
                "tool_usage_summary": agent_result.get("tool_usage_summary", {}),
                "messages_count": agent_result.get("messages_count", 0),
                "trace_id": agent_result.get("trace_id")
            }
        except Exception as e:
            error_msg = f"Agent execution failed: {str(e)}"
            print(f"\n‚ùå Agent Error: {error_msg}")
            import traceback
            print(f"   Traceback:\n{traceback.format_exc()}")
            raise HTTPException(
                status_code=500,
                detail=error_msg
            )
        
        # Extract CSV from response (remove markdown code blocks if present)
        print(f"\nüìÑ [CSV EXTRACTION] Extracting CSV from agent response")
        print(f"   üìè Agent response length: {len(agent_response)} characters")
        print(f"   üìã Full agent response:\n{'='*80}\n{agent_response}\n{'='*80}")
        
        csv_content = agent_response.strip()
        
        # Try to extract CSV from markdown code blocks
        if "```csv" in csv_content:
            print(f"   üîç Found markdown CSV block (```csv)")
            parts = csv_content.split("```csv")
            if len(parts) > 1:
                csv_content = parts[1].split("```")[0].strip()
                print(f"   ‚úÖ Extracted CSV from markdown block")
        elif "```" in csv_content:
            print(f"   üîç Found generic markdown code block (```)")
            # Look for CSV content between code blocks
            parts = csv_content.split("```")
            for i, part in enumerate(parts):
                if i % 2 == 1:  # Odd indices are code blocks
                    if "test_object" in part and "," in part:
                        csv_content = part.strip()
                        print(f"   ‚úÖ Extracted CSV from code block")
                        break
        
        # If still no CSV header found, try to find lines starting with CSV header
        if "test_object" not in csv_content:
            print(f"   ‚ö†Ô∏è  'test_object' not found in content, searching for header pattern...")
            # Look for CSV header pattern in the response
            lines = csv_content.split('\n')
            header_line_idx = None
            for idx, line in enumerate(lines):
                if 'test_object' in line.lower() and ',' in line:
                    header_line_idx = idx
                    print(f"   ‚úÖ Found header at line {idx}: {line[:100]}")
                    break
            
            if header_line_idx is not None:
                csv_content = '\n'.join(lines[header_line_idx:])
            else:
                print(f"   ‚ùå No CSV header found in response")
        
        # Clean up: remove any leading text before the header
        # Look for header starting with test_object (id column is optional/removed)
        if "test_object," in csv_content:
            # Find the header line
            lines = csv_content.split('\n')
            for idx, line in enumerate(lines):
                if line.strip().startswith("test_object,"):
                    csv_content = '\n'.join(lines[idx:])
                    print(f"   ‚úÖ Cleaned CSV starting from header line {idx}")
                    break
        
        print(f"\n   üìã Final CSV content to parse ({len(csv_content)} chars):")
        print(f"   {'='*80}")
        print(csv_content[:1000] if len(csv_content) > 1000 else csv_content)
        print(f"   {'='*80}")
        
        # Parse CSV and validate with Pydantic
        print(f"\nüìã [CSV PARSING] Parsing CSV content")
        print(f"   üìç Stage: Parsing and validating CSV")
        print(f"   üìè CSV content length: {len(csv_content)} characters")
        print(f"   üìã CSV content lines: {len(csv_content.split(chr(10)))}")
        
        try:
            csv_reader = csv.DictReader(io.StringIO(csv_content))
            # Log the detected columns
            if csv_reader.fieldnames:
                print(f"   üìä Detected CSV columns: {csv_reader.fieldnames}")
            else:
                print(f"   ‚ö†Ô∏è  No columns detected in CSV!")
            print(f"   ‚úÖ CSV parsed successfully")
        except Exception as e:
            # If CSV parsing fails, return error with proper status code
            error_msg = f"Failed to parse CSV: {str(e)}. Agent response preview: {agent_response[:500]}"
            print(f"\n‚ùå CSV Parsing Error: {error_msg}")
            raise HTTPException(
                status_code=422, 
                detail=error_msg
            )
        validated_rows = []
        invalid_rows = []
        
        # Convert csv_reader to list to check if it's empty and allow multiple iterations
        rows_list = list(csv_reader)
        print(f"   üìä Total rows read from CSV: {len(rows_list)}")
        
        if len(rows_list) == 0:
            print(f"   ‚ö†Ô∏è  WARNING: CSV reader returned 0 rows!")
            print(f"   üìã CSV content was:\n{csv_content}")
            raise HTTPException(
                status_code=422,
                detail=f"No data rows found in CSV. CSV content: {csv_content[:200]}"
            )
        
        print(f"   üîç Validating rows with Pydantic...")
        for idx, row in enumerate(rows_list, start=2):  # Start at 2 (header is row 1)
            print(f"   üìù Processing row {idx}: {dict(row)}")
            try:
                # Convert empty strings to None for optional fields (except numeric fields)
                cleaned_row = {}
                for k, v in row.items():
                    # Skip id if present (auto-generated by database)
                    if k == 'id':
                        continue
                    # Skip reference_unit if present (removed from schema)
                    if k == 'reference_unit':
                        continue
                    cleaned_row[k] = (v if v else None)
                
                # Convert numeric fields - must be valid floats if present
                if cleaned_row.get('result_value'):
                    try:
                        cleaned_row['result_value'] = float(cleaned_row['result_value'])
                    except (ValueError, TypeError) as e:
                        raise ValueError(f"result_value must be a valid float, got: {cleaned_row.get('result_value')}")
                else:
                    cleaned_row['result_value'] = None
                
                if cleaned_row.get('reference_value'):
                    try:
                        cleaned_row['reference_value'] = float(cleaned_row['reference_value'])
                    except (ValueError, TypeError) as e:
                        raise ValueError(f"reference_value must be a valid float, got: {cleaned_row.get('reference_value')}")
                else:
                    cleaned_row['reference_value'] = None
                
                # Validate with Pydantic
                validated_row = TestingResultRow(**cleaned_row)
                validated_rows.append(validated_row.model_dump())
                if idx % 10 == 0 or idx == 2:  # Log every 10th row or first row
                    print(f"   ‚úÖ Validated row {idx}")
            except Exception as e:
                # Collect invalid row info but continue processing
                invalid_row_info = {
                    "row_number": idx,
                    "error": str(e),
                    "row_data": dict(row)  # Store original row data for logging
                }
                invalid_rows.append(invalid_row_info)
                print(f"   ‚ö†Ô∏è  Row {idx} INVALID - will be skipped: {str(e)}")
                # Log the problematic row data
                test_obj = row.get('test_object', 'N/A')
                result_val = row.get('result_value', 'N/A')
                print(f"      Row data: test_object='{test_obj}', result_value='{result_val}'")
        
        # Log summary of invalid rows
        if invalid_rows:
            print(f"\n‚ö†Ô∏è  VALIDATION SUMMARY - Invalid Rows Removed:")
            print(f"   Total invalid rows: {len(invalid_rows)}")
            print(f"   Invalid row numbers: {[r['row_number'] for r in invalid_rows]}")
            for invalid_row in invalid_rows:
                print(f"   ‚ùå Row {invalid_row['row_number']}: {invalid_row['error']}")
                test_obj = invalid_row['row_data'].get('test_object', 'N/A')
                result_val = invalid_row['row_data'].get('result_value', 'N/A')
                print(f"      Data: test_object='{test_obj}', result_value='{result_val}'")
        
        if not validated_rows:
            error_msg = "No valid rows found in CSV after validation"
            print(f"\n‚ùå Validation Error: {error_msg}")
            if invalid_rows:
                print(f"   All {len(invalid_rows)} rows were invalid and removed")
            raise HTTPException(
                status_code=422,
                detail=error_msg
            )
        
        # Log success summary
        print(f"\n‚úÖ VALIDATION SUMMARY - Valid Rows:")
        print(f"   Total valid rows: {len(validated_rows)}")
        if invalid_rows:
            print(f"   Total invalid rows removed: {len(invalid_rows)}")
            print(f"   Success rate: {len(validated_rows)}/{len(validated_rows) + len(invalid_rows)} ({100 * len(validated_rows) / (len(validated_rows) + len(invalid_rows)):.1f}%)")
        
        # Insert into database
        print(f"\nüíæ [DATABASE WRITE] psql_client.write()")
        print(f"   üìç Stage: Writing to PostgreSQL database")
        if not psql_client:
            print(f"   ‚ùå Error: Database connection not available")
            raise HTTPException(status_code=500, detail="Database connection not available")
        
        print(f"   üìä Preparing DataFrame with {len(validated_rows)} rows")
        df = pd.DataFrame(validated_rows)
        print(f"   üìã DataFrame columns: {', '.join(df.columns.tolist())}")
        print(f"   üìè DataFrame shape: {df.shape[0]} rows √ó {df.shape[1]} columns")
        
        print(f"\n   üíæ Database Write Parameters:")
        print(f"      Table: public.testing_results")
        print(f"      Write disposition: append")
        print(f"      Conflict handling: error (all rows will be inserted)")
        print(f"      Rows to insert: {len(df)}")
        print(f"      Note: 'id' column will be auto-generated by database")
        
        print(f"   üîå Connecting to database...")
        try:
            # Note: id is auto-generated, so we use 'error' conflict handling which doesn't require index_columns
            # This will insert all rows (duplicates allowed since id is auto-generated)
            psql_client.write(
                df,
                "testing_results",
                "public",
                write_disposition="append",
                on_conflict="error"
            )
            print(f"   ‚úÖ Successfully inserted {len(validated_rows)} rows into database")
            print(f"   üìä Database operation completed")
        except Exception as e:
            print(f"   ‚ùå Database write error: {str(e)}")
            import traceback
            print(f"   üìã Traceback:\n{traceback.format_exc()}")
            raise HTTPException(
                status_code=500,
                detail=f"Database write failed: {str(e)}"
            )
        
        # Log final statistics
        print("\n" + "=" * 80)
        print("üìä API RESPONSE STATISTICS")
        print("=" * 80)
        print(f"‚úÖ Success: True")
        print(f"üìù Message: Successfully inserted {len(validated_rows)} rows")
        print(f"üìä Rows Inserted: {len(validated_rows)}")
        if invalid_rows:
            print(f"‚ö†Ô∏è  Invalid Rows Removed: {len(invalid_rows)}")
            print(f"üìã Invalid Row Numbers: {[r['row_number'] for r in invalid_rows]}")
        print(f"üîß Tool Calls: {len(trace_info.get('tool_calls', []))}")
        print(f"üì® Messages: {trace_info.get('messages_count', 0)}")
        if trace_info.get('tool_usage_summary'):
            print(f"üìã Tool Usage: {json.dumps(trace_info['tool_usage_summary'], indent=2)}")
        print("=" * 80 + "\n")
        
        response_message = f"Successfully inserted {len(validated_rows)} rows"
        if invalid_rows:
            response_message += f" ({len(invalid_rows)} invalid rows were removed)"
        
        return {
            "success": True,
            "message": response_message,
            "rows_inserted": len(validated_rows),
            "rows_invalid": len(invalid_rows) if invalid_rows else 0,
            "invalid_row_numbers": [r['row_number'] for r in invalid_rows] if invalid_rows else [],
            "trace": trace_info
        }
        
    except HTTPException:
        raise
    except Exception as e:
        error_msg = f"Error processing file: {str(e)}"
        print(f"\n‚ùå Unexpected Error: {error_msg}")
        import traceback
        print(f"   Traceback:\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=error_msg)


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=3002)

